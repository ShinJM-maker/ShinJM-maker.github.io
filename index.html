<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Joongmin Shin | LLM & Document AI</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="description" content="LLM/LVLM research scientist and Document AI engineer building multimodal RAG, parsing, and hybrid QA systems." />
  <link rel="canonical" href="https://ShinJM-maker.github.io/" />
  <meta property="og:title" content="Joongmin Shin | LLM & Document AI" />
  <meta property="og:description" content="LLM/LVLM research scientist and Document AI engineer building multimodal RAG, parsing, and hybrid QA systems." />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="https://ShinJM-maker.github.io/" />
  <meta property="og:image" content="https://ShinJM-maker.github.io/og-image.svg" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />
  <meta property="og:image:type" content="image/svg+xml" />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Joongmin Shin | LLM & Document AI" />
  <meta name="twitter:description" content="LLM/LVLM research scientist and Document AI engineer building multimodal RAG, parsing, and hybrid QA systems." />
  <meta name="twitter:image" content="https://ShinJM-maker.github.io/og-image.svg" />
  <link rel="icon" href="/favicon.svg" type="image/svg+xml" />
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <header>
    <div class="header-inner">
      <div class="header-main">
        <div>
          <h1>Joongmin Shin</h1>
          <h2>LLM/LVLM Research Scientist &amp; Document AI Engineer</h2>
          <div class="meta-block">
            Seoul, Republic of Korea ¬∑ Open to relocation (US/EU) and remote roles
          </div>
          <div class="meta-block">
            (+82) 10-5710-8702 ¬∑
            <a href="mailto:tlswndals13@korea.ac.kr">tlswndals13@korea.ac.kr</a>
          </div>
        </div>
        <div class="link-row">
          <a class="link-pill" href="https://github.com/shinjm-maker" target="_blank" rel="noreferrer" aria-label="GitHub profile">
            <span class="icon">üêô</span><span>GitHub</span>
          </a>
          <a class="link-pill" href="https://shinjm-maker.github.io" target="_blank" rel="noreferrer" aria-label="Portfolio homepage">
            <span class="icon">üß™</span><span>Portfolio</span>
          </a>
          <a class="link-pill" href="https://www.linkedin.com/in/shinjm-maker" target="_blank" rel="noreferrer" aria-label="LinkedIn profile">
            <span class="icon">üîó</span><span>LinkedIn</span>
          </a>
        </div>
      </div>

      <nav class="top-nav">
        <a href="#home">Home</a>
        <a href="#featured">Featured</a>
        <a href="#projects">Projects</a>
        <a href="#research-map">Research Map</a>
        <a href="#publications">Publications</a>
        <a href="#experience">Experience</a>
        <a href="#contact">Contact</a>
      </nav>
    </div>
  </header>

  <main>
    <!-- Hero -->
    <section id="home" class="hero">
      <div class="hero-text">
        <h1>Joongmin Shin</h1>
        <p>Research scientist focused on structure-aware RAG, multimodal parsing, and explainable QA for industrial long documents.</p>
        <ul>
          <li>Turn noisy PDFs/scans into trees, graphs, and chunks that LLMs can reason over.</li>
          <li>Design hierarchical retrieval and routing to keep answers grounded and token-efficient.</li>
          <li>Ship applied pilots in power, insurance, healthcare with measurable search/QA gains.</li>
        </ul>
        <div class="hero-actions">
          <a class="cta-btn" href="mailto:tlswndals13@korea.ac.kr">Email</a>
          <a class="cta-btn secondary" href="https://github.com/shinjm-maker" target="_blank" rel="noreferrer">GitHub</a>
          <a class="cta-btn secondary" href="https://www.linkedin.com/in/shinjm-maker" target="_blank" rel="noreferrer">LinkedIn</a>
        </div>
        <div class="hero-meta">
          <div class="hero-card">
            <strong>Current Focus</strong>
            <div class="item-sub">Hierarchical retrieval + multimodal chunking for long industrial docs.</div>
            <div class="chips">
              <span class="chip emph">RAG</span><span class="chip">LVLM</span><span class="chip">Routing</span>
            </div>
          </div>
          <div class="hero-card">
            <strong>Background</strong>
            <div class="item-sub">5+ years building applied RAG/LVLM systems; first-author EMNLP 2024/2025; patents and national grants.</div>
          </div>
          <div class="hero-card">
            <strong>Latest</strong>
            <div class="item-sub">Project Orion &amp; Project Vega (under review), MultiDocFusion (EMNLP 2025).</div>
          </div>
          <div class="hero-card">
            <strong>What I value</strong>
            <div class="item-sub">Token-efficiency, explainability, and measurable gains in real deployments.</div>
          </div>
        </div>
      </div>
      <img class="hero-avatar" src="profile_picture.png" alt="Profile portrait" />
    </section>

    <!-- Featured -->
    <section id="featured">
      <h3>
        Featured Work
        <span class="em">Recent Highlights</span>
      </h3>
      <div class="featured-grid">
        <div class="featured-card">
          <div class="featured-title">Project Orion</div>
          <div class="featured-meta">Hierarchical multimodal retrieval ¬∑ Under review</div>
          <div class="featured-tags chips">
            <span class="chip emph">RAG</span><span class="chip">Routing</span><span class="chip">Multimodal</span>
          </div>
          <p class="item-sub">Coarse-to-fine routing and evidence assembly for open-domain document QA on industrial corpora.</p>
        </div>
        <div class="featured-card">
          <div class="featured-title">Project Vega</div>
          <div class="featured-meta">Multimodal dependency chunking ¬∑ Under review</div>
          <div class="featured-tags chips">
            <span class="chip emph">Chunking</span><span class="chip">LVLM</span><span class="chip">Structure</span>
          </div>
          <p class="item-sub">Shared parsing frame + doc-tree reconstruction to create boundary-aware chunks for long scans.</p>
        </div>
        <div class="featured-card">
          <div class="featured-title">MultiDocFusion</div>
          <div class="featured-meta">EMNLP 2025 ¬∑ Structure-aware chunking</div>
          <div class="featured-tags chips">
            <span class="chip emph">RAG</span><span class="chip">Layout</span><span class="chip">LLM</span>
          </div>
          <p class="item-sub">Vision parsing + OCR + hierarchy reconstruction to keep document structure in retrieval.</p>
        </div>
        <div class="featured-card">
          <div class="featured-title">SynerPeace</div>
          <div class="featured-meta">Insurance QA + workflows</div>
          <div class="featured-tags chips">
            <span class="chip emph">Applied LLM</span><span class="chip">Workflow</span><span class="chip">QA</span>
          </div>
          <p class="item-sub">LLM QA and automation for insurance agents; won Samsung F&amp;M pilot grand prize.</p>
        </div>
      </div>
    </section>

    <!-- Professional Experience -->
    <section id="experience">
      <h3>
        Professional Experience
        <span class="em">Industry &amp; Research</span>
      </h3>

      <!-- Korea University -->
      <article class="item">
        <div class="item-header">
          <span class="place">Senior Researcher / Research Scientist ¬∑ Human-Inspired AI Research, Korea University</span>
          <span class="time">Jun 2023 ‚Äì Present ¬∑ Seoul, Republic of Korea</span>
        </div>
        <p class="item-sub">Multimodal RAG ¬∑ Document Parsing ¬∑ Hybrid QA Systems</p>
        <ul>
          <li><strong>Impact:</strong> Piloted multimodal RAG for power, insurance, healthcare; cut manual search ~<strong>40%</strong> and improved hybrid QA accuracy ~<strong>10%</strong>.</li>
          <li><strong>Role:</strong> Led structure-aware chunking/LVLM parsing; first-authored <strong>StyleDFS</strong> (EMNLP 2024) and <strong>MultiDocFusion</strong> (EMNLP 2025); managed partners (Samsung F&amp;M, Hyundai Mobis, KIGAM).</li>
          <li><strong>Tech:</strong> LVLM parsing, structure-aware chunking, knowledge graphs + LLMs, RAG/GraphRAG.</li>
        </ul>
      </article>

      <!-- PNU AI Lab -->
      <article class="item">
        <div class="item-header">
          <span class="place">Researcher (M.S.) ¬∑ AI Lab, Pusan National University</span>
          <span class="time">Sep 2020 ‚Äì Feb 2023 ¬∑ Busan, Republic of Korea</span>
        </div>
        <p class="item-sub">Korean Dependency Parsing ¬∑ Table QA ¬∑ Prosody Prediction</p>
        <ul>
          <li><strong>Impact:</strong> Delivered neural‚Äìsymbolic Korean dependency parsers used as backbone for sentence/table QA; reached state-of-the-art Korean Table QA; earned an <strong>Outstanding Paper Award</strong>.</li>
          <li><strong>Role:</strong> Led parsing and table QA pipelines for Exobrain; collaborated on syntax-aware TTS prosody.</li>
          <li><strong>Tech:</strong> Neural‚Äìsymbolic dependency parsing, table QA on finance/encyclopedic data, TTS prosody modeling.</li>
        </ul>
      </article>

      <!-- SW Education Center -->
      <article class="item">
        <div class="item-header">
          <span class="place">Researcher ¬∑ SW Education Center, Pusan National University</span>
          <span class="time">Mar 2020 ‚Äì Aug 2020 ¬∑ Busan, Republic of Korea</span>
        </div>
        <p class="item-sub">Education Technology ¬∑ Web Development</p>
        <ul>
          <li><strong>Impact:</strong> Delivered a Django-based online judge with auto-grading and personalized recommendations for programming courses.</li>
          <li><strong>Role:</strong> Built core platform features end-to-end.</li>
          <li><strong>Tech:</strong> Django, auto-grading pipelines, recommendation logic.</li>
        </ul>
      </article>
    </section>

    <!-- Selected Research & Industry Projects -->
    <section id="projects">
      <h3>
        Selected Projects
        <span class="em">RAG ¬∑ LVLM ¬∑ Applied LLMs</span>
      </h3>

      <!-- CVPR_Doc -->
      <article class="item">
        <div class="item-header">
          <span class="place">LVLM-based Document Parsing for Large-Scale Industrial Documents (CVPR_Doc)</span>
          <span class="time">Jul 2025 ‚Äì Present</span>
        </div>
        <p class="item-sub">Senior Researcher ¬∑ Korea University ¬∑ Seoul, Republic of Korea</p>
        <div class="chips">
          <span class="chip emph">LVLM</span>
          <span class="chip">Document Parsing</span>
          <span class="chip">RAG</span>
        </div>
        <ul>
          <li><strong>Impact:</strong> LVLM parsing for noisy industrial PDFs/scans; outputs document-level trees/graphs for RAG; preparing CVPR 2026 submission.</li>
          <li><strong>Role:</strong> Research design, LVLM fine-tuning, prototype implementation.</li>
          <li><strong>Tech:</strong> LVLMs, document parsing, structure-aware retrieval.</li>
        </ul>
      </article>

      <!-- MultiDocFusion -->
      <article class="item">
        <div class="item-header">
          <span class="place">MultiDocFusion: Structure-Aware Multimodal Chunking for Real-World Documents</span>
          <span class="time">Jan 2025 ‚Äì Jul 2025</span>
        </div>
        <p class="item-sub">Senior Researcher ¬∑ Korea University ¬∑ Seoul, Republic of Korea</p>
        <div class="chips">
          <span class="chip emph">RAG</span>
          <span class="chip">Chunking</span>
          <span class="chip">Multimodal</span>
        </div>
        <ul>
          <li><strong>Impact:</strong> Multimodal chunking that preserves layout hierarchies for long, noisy PDFs; improved retrieval quality.</li>
          <li><strong>Role:</strong> Research design, modeling, prototype implementation.</li>
          <li><strong>Outcome/Tech:</strong> EMNLP 2025 Main (<em>MultiDocFusion</em>); structure-aware chunking, RAG.</li>
        </ul>
      </article>

      <!-- StyleDFS -->
      <article class="item">
        <div class="item-header">
          <span class="place">Korean Science-Domain LLM and RAG Pipeline (StyleDFS)</span>
          <span class="time">Feb 2024 ‚Äì Dec 2024</span>
        </div>
        <p class="item-sub">Senior Researcher ¬∑ Korea University ¬∑ Seoul, Republic of Korea</p>
        <div class="chips">
          <span class="chip emph">Domain LLM</span>
          <span class="chip">Scientific Literature</span>
          <span class="chip">RAG</span>
        </div>
        <ul>
          <li><strong>Impact:</strong> Korean LLM + RAG pipeline for scientific literature with domain preprocessing/chunking; transferred twice.</li>
          <li><strong>Role:</strong> Data pipeline and chunking algorithm design/implementation.</li>
          <li><strong>Outcome/Tech:</strong> EMNLP 2024 Industry (<em>StyleDFS</em>); structure-aware chunking, domain LLM.</li>
        </ul>
      </article>

      <!-- PLC Programming Assistant -->
      <article class="item">
        <div class="item-header">
          <span class="place">GPT-based PLC Programming Assistant PoC for Smart Factories</span>
          <span class="time">Sep 2023 ‚Äì Feb 2024</span>
        </div>
        <p class="item-sub">Senior Researcher ¬∑ Korea University &amp; Hyundai Mobis ¬∑ Seoul, Republic of Korea</p>
        <div class="chips">
          <span class="chip emph">Code Generation</span>
          <span class="chip">Smart Factory</span>
        </div>
        <ul>
          <li><strong>Impact:</strong> LLM-based PLC programming assistant PoC validated with Hyundai Mobis.</li>
          <li><strong>Role:</strong> Architecture design and code-generation model implementation.</li>
          <li><strong>Tech:</strong> Code LLaMA, PLC templates, assisted code generation.</li>
        </ul>
      </article>

      <!-- Synapse -->
      <article class="item">
        <div class="item-header">
          <span class="place">LLM-based Multilingual Medical Consultation Service ‚ÄúSynapse‚Äù</span>
          <span class="time">Jun 2023 ‚Äì Jan 2024</span>
        </div>
        <p class="item-sub">Senior Researcher ¬∑ Korea University &amp; Synapse ¬∑ Seoul, Republic of Korea</p>
        <div class="chips">
          <span class="chip emph">Chatbot</span>
          <span class="chip">Multilingual</span>
          <span class="chip">Healthcare</span>
        </div>
        <ul>
          <li><strong>Impact:</strong> Multilingual medical consultation chatbot with conversational/document QA; selected for KU-Grant Excellent Technology Track.</li>
          <li><strong>Role:</strong> Chatbot design plus backend/admin console (React, Express, PostgreSQL).</li>
          <li><strong>Tech:</strong> LangChain, React, Express, PostgreSQL.</li>
        </ul>
      </article>

      <!-- SynerPeace -->
      <article class="item">
        <div class="item-header">
          <span class="place">LLM-based Insurance Assistant ‚ÄúSynerPeace‚Äù Pilot Project</span>
          <span class="time">Jul 2023 ‚Äì Jan 2024</span>
        </div>
        <p class="item-sub">Senior Researcher ¬∑ Korea University &amp; Samsung Fire &amp; Marine Insurance ¬∑ Seoul, Republic of Korea</p>
        <div class="chips">
          <span class="chip emph">Insurance</span>
          <span class="chip">Workflow Automation</span>
        </div>
        <ul>
          <li><strong>Impact:</strong> ‚ÄúSynerPeace‚Äù LLM app for insurance support/workflows; won Samsung F&amp;M pilot grand prize with follow-up investment.</li>
          <li><strong>Role:</strong> AI model architecture and LLM application development.</li>
          <li><strong>Tech:</strong> LLM QA over domain docs, workflow automation.</li>
        </ul>
      </article>

      <!-- Exobrain WiseQA -->
      <article class="item">
        <div class="item-header">
          <span class="place">Exobrain WiseQA: Neuro-Symbolic Question Answering Platform</span>
          <span class="time">Sep 2020 ‚Äì Dec 2022</span>
        </div>
        <p class="item-sub">Researcher (M.S.) ¬∑ Pusan National University &amp; ETRI ¬∑ Busan, Republic of Korea</p>
        <div class="chips">
          <span class="chip emph">Neuro-Symbolic QA</span>
          <span class="chip">Knowledge Graphs</span>
        </div>
        <ul>
          <li><strong>Impact:</strong> Neural‚Äìsymbolic models for Korean sentence analysis/Table QA; produced multiple conference papers.</li>
          <li><strong>Role:</strong> Model design, implementation, experimentation; continual-learning MRC research.</li>
          <li><strong>Tech:</strong> Rules + knowledge graphs + language models for QA.</li>
        </ul>
      </article>
    </section>

    <!-- Research Map -->
    <section id="research-map">
      <h3>
        Research Map
        <span class="em">Flow</span>
      </h3>
      <figure class="research-figure full-bleed">
        <img src="Research_history.svg" alt="Research history map" class="research-image" />
        <figcaption class="item-sub">Research evolution across syntax ‚Üí applied LLM/RAG ‚Üí multimodal doc intelligence ‚Üí future agentic AI.</figcaption>
        <button class="research-link research-lightbox-trigger" data-src="Research_history.svg" type="button">Open full size</button>
      </figure>
      <div class="lightbox" id="research-lightbox" aria-hidden="true">
        <div class="lightbox-content">
          <button class="lightbox-close" type="button" aria-label="Close">‚úï</button>
          <img src="Research_history.svg" alt="Research history map full size" />
        </div>
      </div>
    </section>

    <!-- Education -->
    <section id="education">
      <h3>
        Education
        <span class="em">Academic Background</span>
      </h3>

      <article class="item">
        <div class="item-header">
          <span class="place">M.S. in Artificial Intelligence ¬∑ Pusan National University</span>
          <span class="time">Mar 2021 ‚Äì Feb 2023 ¬∑ Busan, Republic of Korea</span>
        </div>
        <p class="item-sub">Graduate School of Artificial Intelligence</p>
        <ul>
          <li>Thesis focused on parsing unstructured data and integrating syntactic/morphological analysis for Korean NLP.</li>
          <li>Participated in national AI projects and filed patents related to hybrid neural‚Äìsymbolic NLP models.</li>
        </ul>
      </article>

      <article class="item">
        <div class="item-header">
          <span class="place">B.S. in Computer Science and Engineering ¬∑ Pusan National University</span>
          <span class="time">Mar 2016 ‚Äì Feb 2021 ¬∑ Busan, Republic of Korea</span>
        </div>
        <p class="item-sub">Department of Computer Science and Engineering</p>
        <ul>
          <li>Completed coursework in software engineering, algorithms, and data analysis.</li>
          <li>Engaged in multiple industry projects and hackathons, building teamwork and leadership skills.</li>
        </ul>
      </article>
    </section>

    <!-- Selected Publications -->
    <section id="publications">
      <h3>
        Selected Publications
        <span class="em">First-author &amp; Key Contributions</span>
      </h3>
      <p class="item-sub">Click a card to toggle the abstract.</p>
      <div class="pub-grid">
        <details class="pub-card">
          <summary>
            <div class="pub-titleline">
              <span class="pub-title">Project Orion (Hierarchical Multimodal Retrieval)</span>
              <span class="pub-badge">Anonymized (Under Review)</span>
            </div>
            <div class="pub-meta">Under review ¬∑ Open-domain RAG ¬∑ Hierarchical routing</div>
            <div class="pub-authors">Anonymous (double-blind)</div>
          </summary>
          <p class="pub-abstract">An anonymized submission building a hierarchical tree-based retrieval pipeline for industrial ODQA, combining document hierarchy parsing, coarse-to-fine routing, and multimodal fusion to prune search space and assemble token-efficient evidence. Gains: recall +12.9%, QA +6.8% over page/chunk baselines.</p>
        </details>

        <details class="pub-card">
          <summary>
            <div class="pub-titleline">
              <span class="pub-title">Project Vega (Multimodal Dependency Chunking)</span>
              <span class="pub-badge">Anonymized (Under Review)</span>
            </div>
            <div class="pub-meta">Under review ¬∑ Multimodal parsing ¬∑ Chunking</div>
            <div class="pub-authors">Anonymous (double-blind)</div>
          </summary>
          <p class="pub-abstract">An anonymized submission introducing shared parsing frame (SharedDet), multimodal block embeddings with SoftROI, and biaffine doc-tree reconstruction to build structure-aware chunks for long industrial scans. Improves DHP and RAG: STEDS +28.5‚Äì39.6%, nDCG +1.1‚Äì15.3%, QA ANLS +4.5‚Äì15.3%.</p>
        </details>

        <details class="pub-card">
          <summary>
            <div class="pub-titleline">
              <span class="pub-title">MultiDocFusion: Hierarchical &amp; Multimodal Chunking Pipeline</span>
              <span class="pub-badge">EMNLP 2025 (Main)</span>
            </div>
            <div class="pub-meta">Long-doc RAG ¬∑ Layout-aware chunking</div>
            <div class="pub-authors">Joongmin Shin*, Chanjun Park, Jeongbae Park, Jaehyung Seo, Heuiseok Lim</div>
          </summary>
          <p class="pub-abstract">Vision parsing + OCR + LLM hierarchy reconstruction + DFS grouping to keep structure in chunks. Boosts retrieval quality and downstream QA on industrial long-doc benchmarks.</p>
        </details>

        <details class="pub-card">
          <summary>
            <div class="pub-titleline">
              <span class="pub-title">Predictive Maintenance RAG for Power Plants (StyleDFS)</span>
              <span class="pub-badge">EMNLP 2024 (Industry)</span>
            </div>
            <div class="pub-meta">Industrial RAG ¬∑ On-premise QA</div>
            <div class="pub-authors">Seongtae Hong*, Joongmin Shin*, Jaehyung Seo, Taemin Lee, Jeongbae Park, Heuiseok Lim</div>
          </summary>
          <p class="pub-abstract">On-prem QA framework for high-stakes plants using StyleDFS chunking and domain instruction tuning to preserve structure and privacy while improving accuracy.</p>
        </details>

        <details class="pub-card">
          <summary>
            <div class="pub-titleline">
              <span class="pub-title">Distance-Based Korean WordNet (KorLex) Embeddings</span>
              <span class="pub-badge">Applied AI 2024</span>
            </div>
            <div class="pub-meta">Lexical graph embeddings</div>
            <div class="pub-authors">SeongReol Park*, Joongmin Shin, Sanghyun Cho, Hyuk-Chul Kwon, Jung-Hun Lee</div>
          </summary>
          <p class="pub-abstract">Maps KorLex into vector space to inject lexical-semantic structure into neural embeddings, improving similarity and analogy behavior over distributional baselines.</p>
        </details>

        <details class="pub-card">
          <summary>
            <div class="pub-titleline">
              <span class="pub-title">Hybrid Reader over Tables and Text</span>
              <span class="pub-badge">Applied AI 2024</span>
            </div>
            <div class="pub-meta">Table + text MRC ¬∑ Hybrid reader</div>
            <div class="pub-authors">Sanghyun Cho*, SeongReol Park, Hye-Lynn Kim, Jung-Hun Lee, Joongmin Shin, Hyuk-Chul Kwon</div>
          </summary>
          <p class="pub-abstract">Single hybrid reader (K-Adapter style) that fuses table knowledge without separate models; outperforms table/text specialists on mixed MRC (e.g., KorQuAD 2.0).</p>
        </details>

        <details class="pub-card">
          <summary>
            <div class="pub-titleline">
              <span class="pub-title">Retrieval-Based Generation Techniques for LLMs</span>
              <span class="pub-badge">KIICE 2023</span>
            </div>
            <div class="pub-meta">RAG vs zero-shot ¬∑ GPT-3.5/4</div>
            <div class="pub-authors">Joongmin Shin*, Jungun Lee</div>
          </summary>
          <p class="pub-abstract">Comparative study of zero-shot vs RAG for GPT-3.5/4; outlines accuracy/reliability gains and practical components for evidence-grounded answers.</p>
        </details>

        <details class="pub-card">
          <summary>
            <div class="pub-titleline">
              <span class="pub-title">QA-Pair Passage RAG for Korean Chatbots</span>
              <span class="pub-badge">HCLT 2023</span>
            </div>
            <div class="pub-meta">Korean chatbot ¬∑ QA-pair RAG</div>
            <div class="pub-authors">Joongmin Shin*, Jaewwok Lee, Kyungmin Kim, Heuiseok Lim</div>
          </summary>
          <p class="pub-abstract">Combines QA-pair passage construction with RAG to cut hallucination and improve accuracy in Korean chatbot services.</p>
        </details>

        <details class="pub-card">
          <summary>
            <div class="pub-titleline">
              <span class="pub-title">Comparative Analysis of Korean LLM Quality (Zero-shot)</span>
              <span class="pub-badge">HCLT 2023</span>
            </div>
            <div class="pub-meta">Korean LLM eval ¬∑ Zero-shot</div>
            <div class="pub-authors">Yunah Huh, Aram So, Taemin Lee, Joongmin Shin, Heuiseok Lim</div>
          </summary>
          <p class="pub-abstract">Benchmarks Korean LLMs across translation, summarization, and QA in zero-shot settings; reports error patterns and practical selection guidance.</p>
        </details>

        <details class="pub-card">
          <summary>
            <div class="pub-titleline">
              <span class="pub-title">Neural-Symbolic Model for Korean Dependency Parsing</span>
              <span class="pub-badge">Master's Thesis ¬∑ 2023</span>
            </div>
            <div class="pub-meta">Parsing ¬∑ Hybrid rules + DL</div>
            <div class="pub-authors">Joongmin Shin*</div>
          </summary>
          <p class="pub-abstract">Hybrid constraint-rule + neural model improves UAS/LAS (up to 96.28/93.19) and trains 11x faster versus larger-data baselines on Modu corpus.</p>
        </details>

        <details class="pub-card">
          <summary>
            <div class="pub-titleline">
              <span class="pub-title">EDT5: Embeddings with T5 Encoder‚ÄìDecoder</span>
              <span class="pub-badge">KSC 2022</span>
            </div>
            <div class="pub-meta">Embeddings ¬∑ Encoder‚Äìdecoder</div>
            <div class="pub-authors">Joongmin Shin*, Joogyoung Jung, Junghoon Lee, Hyuk-Chul Kwon</div>
          </summary>
          <p class="pub-abstract">Leverages T5 decoder representations alongside encoder to improve embedding quality versus encoder-only baselines.</p>
        </details>

        <details class="pub-card">
          <summary>
            <div class="pub-titleline">
              <span class="pub-title">Generalization of Korean Table MRC</span>
              <span class="pub-badge">KSC 2022</span>
            </div>
            <div class="pub-meta">Table MRC ¬∑ Domain generalization</div>
            <div class="pub-authors">Hyelin Kim*, Sanghyun Cho, Joongmin Shin, Hyuk-Chul Kwon</div>
          </summary>
          <p class="pub-abstract">Adversarial and table-specialized embeddings to improve cross-domain table MRC performance across evaluation sets.</p>
        </details>

        <details class="pub-card">
          <summary>
            <div class="pub-titleline">
              <span class="pub-title">Constraint-Enhanced Dependency Parsing</span>
              <span class="pub-badge">HCLT 2022</span>
            </div>
            <div class="pub-meta">Parsing ¬∑ Rules + DL</div>
            <div class="pub-authors">Joongmin Shin*, Hyuk-Chul Kwon</div>
          </summary>
          <p class="pub-abstract">Reinforces governor‚Äìdependent constraints within neural parsers to boost UAS/LAS while using smaller datasets.</p>
        </details>

        <details class="pub-card">
          <summary>
            <div class="pub-titleline">
              <span class="pub-title">ANN-Based Dependency Parsing with Rules</span>
              <span class="pub-badge">KCC 2022</span>
            </div>
            <div class="pub-meta">Parsing ¬∑ Korean</div>
            <div class="pub-authors">Joongmin Shin*, Sanghyun Cho, Bongwoo Nam, Hyuk-Chul Kwon</div>
          </summary>
          <p class="pub-abstract">Adds linguistic rule-based features to neural dependency parsing, improving UAS/LAS on Korean benchmarks.</p>
        </details>

        <details class="pub-card">
          <summary>
            <div class="pub-titleline">
              <span class="pub-title">Continual Learning for Korean MRC</span>
              <span class="pub-badge">HCLT 2021</span>
            </div>
            <div class="pub-meta">MRC ¬∑ Continual learning</div>
            <div class="pub-authors">Joongmin Shin*, Sanghyun Cho, Hyuk-Chul Kwon</div>
          </summary>
          <p class="pub-abstract">Applies continual learning (incl. LwF) to Korean MRC; improves KorQuAD 1.0 F1/EM over BERT baselines.</p>
        </details>
      </div>
    </section>

    <!-- Honors & Awards -->
    <section id="awards">
      <h3>
        Honors &amp; Awards
        <span class="em">Selected Recognition</span>
      </h3>
      <ul class="awards-list">
        <li>
          <div class="award-main">Deputy Prime Minister and Minister of Education Award</div>
          <div class="award-org">Competition for Best Practices in Academia‚ÄìIndustry Cooperation ¬∑ National Research Foundation of Korea (NRF)</div>
          <div class="award-year">2024</div>
        </li>
        <li>
          <div class="award-main">Outstanding Paper Presentation Award</div>
          <div class="award-org">Korean Institute of Information Scientists and Engineers (KIISE 2023)</div>
          <div class="award-year">2023</div>
        </li>
        <li>
          <div class="award-main">Grand Prize</div>
          <div class="award-org">Samsung Fire &amp; Marine Insurance LLM-based MVP Model Idea Competition</div>
          <div class="award-year">2023</div>
        </li>
        <li>
          <div class="award-main">Excellence Award (Technology Track)</div>
          <div class="award-org">KU-Grant Program ¬∑ Korea University</div>
          <div class="award-year">2023</div>
        </li>
        <li>
          <div class="award-main">Outstanding Paper Presentation Award</div>
          <div class="award-org">Korea Software Congress (KSC 2022)</div>
          <div class="award-year">2022</div>
        </li>
        <li>
          <div class="award-main">Excellence Award</div>
          <div class="award-org">Student-led Research Project, Graduate School of AI ¬∑ Pusan National University</div>
          <div class="award-year">2022</div>
        </li>
        <li>
          <div class="award-main">Milestone Scholarship (Grade A)</div>
          <div class="award-org">SW-centered University Milestone Scholarship Program ¬∑ Pusan National University</div>
          <div class="award-year">2020</div>
        </li>
      </ul>
    </section>

    <!-- Technical Skills -->
    <section id="skills">
      <h3>
        Technical Skills
        <span class="em">Tools &amp; Capabilities</span>
      </h3>
      <div class="grid-2">
        <div>
          <div class="skills-group">
            <strong>Programming</strong>
            <span>Python, C/C++, Java, C#, Django, React, Unity</span>
          </div>
          <div class="skills-group">
            <strong>Machine Learning</strong>
            <span>LLM/LVLM fine-tuning, hybrid rule‚Äìneural models, knowledge graphs</span>
          </div>
          <div class="skills-group">
            <strong>Tools</strong>
            <span>PyTorch, TensorFlow, NumPy, Pandas, Scikit-Learn, LangChain, SQL, Linux</span>
          </div>
        </div>
        <div>
          <div class="skills-group">
            <strong>Project Management</strong>
            <span>Team leadership, cross-functional collaboration, proposal writing</span>
          </div>
          <div class="skills-group">
            <strong>Languages</strong>
            <span>Korean (native), English (fluent reading/writing)</span>
          </div>
        </div>
      </div>
    </section>

    <!-- Teaching & Mentoring -->
    <section id="teaching">
      <h3>
        Teaching &amp; Mentoring
        <span class="em">Academic Involvement</span>
      </h3>
      <article class="item">
        <div class="item-header">
          <span class="place">Graduate Research Mentor ¬∑ Pusan National University</span>
          <span class="time">2021 ‚Äì 2022 ¬∑ Busan, Republic of Korea</span>
        </div>
        <p class="item-sub">Mentoring ¬∑ Education Support</p>
        <ul>
          <li><strong>Impact:</strong> Guided capstones on Korean dependency parsing and Table QA to near state-of-the-art results.</li>
          <li><strong>Role:</strong> Mentored research, provided course/project feedback.</li>
          <li><strong>Tech:</strong> NLP parsing, QA evaluation, web/mobile app guidance.</li>
        </ul>
      </article>
    </section>

    <!-- Contact -->
    <section id="contact">
      <h3>
        Contact
        <span class="em">Let‚Äôs Talk</span>
      </h3>
      <div class="contact-grid">
        <div class="contact-card">
          <strong>Email</strong>
          <div class="item-sub"><a href="mailto:tlswndals13@korea.ac.kr">tlswndals13@korea.ac.kr</a></div>
        </div>
        <div class="contact-card">
          <strong>Phone</strong>
          <div class="item-sub">(+82) 10-5710-8702</div>
        </div>
        <div class="contact-card">
          <strong>Links</strong>
          <div class="item-sub">
            <a href="https://github.com/shinjm-maker" target="_blank" rel="noreferrer">GitHub</a> ¬∑
            <a href="https://www.linkedin.com/in/shinjm-maker" target="_blank" rel="noreferrer">LinkedIn</a>
          </div>
        </div>
        <div class="contact-card">
          <strong>Location</strong>
          <div class="item-sub">Seoul, Republic of Korea (open to relocation/remote)</div>
        </div>
      </div>
    </section>
  </main>
  <button class="back-to-top" type="button" aria-label="Back to top">‚Üë</button>
  <script src="script.js"></script>
</body>
</html>
